{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### The Power of Imputers in ML\n\n\nMissing data happens when some values, like age or salary, are not recorded in a dataset. To fix this, we use data imputation, which means filling in the missing spots with smart guesses like the average or most common value. This helps keep the data complete so machine learning models can work better and make accurate predictions.\n\n### Why Is Data Imputation Important?\nWhen we have missing data in our dataset, it can lead to inaccurate predictions or even cause our model to fail. Simply ignoring or removing data entries with missing values isn't always the best solution, especially if the missing data is a small part of a large and otherwise valuable dataset. By imputing, or filling in, the missing data, we can make better use of our dataset and improve the overall accuracy of our machine learning model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:37:04.315334Z","iopub.execute_input":"2026-01-06T13:37:04.315668Z","iopub.status.idle":"2026-01-06T13:37:06.627286Z","shell.execute_reply.started":"2026-01-06T13:37:04.315626Z","shell.execute_reply":"2026-01-06T13:37:06.626199Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### create a data to understand the data imputation","metadata":{}},{"cell_type":"code","source":"data = {'age':[25, np.nan, 30, np.nan, 35],\n        'salary': [50000, 60000, np.nan,90000, np.nan]}\n\ndataframe = pd.DataFrame(data)\ndataframe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:40:20.303390Z","iopub.execute_input":"2026-01-06T13:40:20.303723Z","iopub.status.idle":"2026-01-06T13:40:20.334570Z","shell.execute_reply.started":"2026-01-06T13:40:20.303698Z","shell.execute_reply":"2026-01-06T13:40:20.333664Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    age   salary\n0  25.0  50000.0\n1   NaN  60000.0\n2  30.0      NaN\n3   NaN  90000.0\n4  35.0      NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25.0</td>\n      <td>50000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>60000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>90000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"### Data imputation via Mean, Median or Mode","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')\nimputed_data = imputer.fit_transform(dataframe)\nimputed_df = pd.DataFrame(imputed_data, columns = dataframe.columns)\nprint(imputed_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:50:09.792916Z","iopub.execute_input":"2026-01-06T13:50:09.793332Z","iopub.status.idle":"2026-01-06T13:50:10.830817Z","shell.execute_reply.started":"2026-01-06T13:50:09.793304Z","shell.execute_reply":"2026-01-06T13:50:10.829682Z"}},"outputs":[{"name":"stdout","text":"    age        salary\n0  25.0  50000.000000\n1  30.0  60000.000000\n2  30.0  66666.666667\n3  30.0  90000.000000\n4  35.0  66666.666667\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### data imputation using knn imputer","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors = 2)\nimputed_data = imputer.fit_transform(dataframe)\nimputed_df = pd.DataFrame(imputed_data, columns = dataframe.columns)\nprint(imputed_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:53:04.726277Z","iopub.execute_input":"2026-01-06T13:53:04.726778Z","iopub.status.idle":"2026-01-06T13:53:04.757462Z","shell.execute_reply.started":"2026-01-06T13:53:04.726753Z","shell.execute_reply":"2026-01-06T13:53:04.756499Z"}},"outputs":[{"name":"stdout","text":"    age   salary\n0  25.0  50000.0\n1  27.5  60000.0\n2  30.0  55000.0\n3  27.5  90000.0\n4  35.0  55000.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Conclusion\nData imputation is a technique to ensure that our machine learning models make the most of the available data. Whether we choose to use mean imputation for its simplicity or KNN imputation for its accuracy, understanding these techniques is crucial for any data scientist. Remember, the choice of method depends on our specific dataset and the nature of the missing values.","metadata":{}}]}